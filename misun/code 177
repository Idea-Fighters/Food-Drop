import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
import gym

# 자율주행 환경 클래스 정의
class SelfDrivingEnv(gym.Env):
    def __init__(self):
        super(SelfDrivingEnv, self).__init__()
        self.observation_space = gym.spaces.Discrete(2)  # 상태 공간 크기: 2 (왼쪽, 오른쪽)
        self.action_space = gym.spaces.Discrete(2)  # 행동 공간 크기: 2 (직진, 회전)
        self.state = 0  # 초기 상태: 왼쪽

    def step(self, action):
        # 행동에 따라 다음 상태 결정
        if action == 0:
            self.state = 0  # 왼쪽으로 이동
        else:
            self.state = 1  # 오른쪽으로 이동

        # 보상 계산
        reward = 1 if self.state == 1 else 0

        # 종료 여부 (항상 False로 설정)
        done = False

        return self.state, reward, done, {}

    def reset(self):
        # 초기 상태로 재설정
        self.state = 0
        return self.state

# DQN 모델 정의
def create_dqn_model():
    model = tf.keras.Sequential([
        layers.Dense(64, activation='relu'),
        layers.Dense(64, activation='relu'),
        layers.Dense(2)  # 출력은 행동 공간 크기와 일치해야 함
    ])
    return model

# DQN 알고리즘을 사용하여 자율주행 학습
def train_dqn(env, num_episodes=1000):
    model = create_dqn_model()
    model.compile(optimizer='adam', loss='mse')

    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0
        done = False

        while not done:
            # epsilon-greedy 정책으로 행동 선택
            epsilon = max(0.1, 0.5 - episode * 0.0009)
            if np.random.rand() < epsilon:
                action = env.action_space.sample()
            else:
                action = np.argmax(model.predict(np.array([state])))

            next_state, reward, done, _ = env.step(action)

            # 샘플 저장 및 학습
            target = reward + 0.99 * np.max(model.predict(np.array([next_state])))
            target_vec = model.predict(np.array([state]))[0]
            target_vec[action] = target
            model.fit(np.array([state]), np.array([target_vec]), verbose=0)

            state = next_state
            total_reward += reward

        print(f"Episode: {episode + 1}, Total Reward: {total_reward}")

# 학습 실행
env = SelfDrivingEnv()
train_dqn(env)
